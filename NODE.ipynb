{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashiqurrahmankhan21st/NODE/blob/main/NODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install Required Packages\n",
        "!pip install torch scikit-learn pandas\n",
        "!pip install optuna\n",
        "# STEP 3: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "TPhU1j2gynR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ae1439-f018-4218-f99e-649a4558af09"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/NODE/refs/heads/main/FFF%20Data.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-2JWFZogA06W",
        "outputId": "26ba89bb-d94b-4924-da22-3892637974ae"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Extruder_temperature  Printing_speed  Infill_density  Layer_height  \\\n",
              "0                   215              90              20           0.2   \n",
              "1                   215              90              10           0.2   \n",
              "2                   215              90               5           0.2   \n",
              "3                   215              90              20           0.2   \n",
              "4                   215              90              10           0.2   \n",
              "\n",
              "   Wall_layer Infill_pattern  Average_tensile_strength  \n",
              "0           3        Diamond                    18.775  \n",
              "1           3        Diamond                     7.625  \n",
              "2           3        Diamond                     4.300  \n",
              "3           3        Diamond                    18.775  \n",
              "4           3        Diamond                     7.625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3caffd64-cfad-4e4d-acb7-48ee89b8f662\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Extruder_temperature</th>\n",
              "      <th>Printing_speed</th>\n",
              "      <th>Infill_density</th>\n",
              "      <th>Layer_height</th>\n",
              "      <th>Wall_layer</th>\n",
              "      <th>Infill_pattern</th>\n",
              "      <th>Average_tensile_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>215</td>\n",
              "      <td>90</td>\n",
              "      <td>20</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3</td>\n",
              "      <td>Diamond</td>\n",
              "      <td>18.775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>215</td>\n",
              "      <td>90</td>\n",
              "      <td>10</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3</td>\n",
              "      <td>Diamond</td>\n",
              "      <td>7.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>215</td>\n",
              "      <td>90</td>\n",
              "      <td>5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3</td>\n",
              "      <td>Diamond</td>\n",
              "      <td>4.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>215</td>\n",
              "      <td>90</td>\n",
              "      <td>20</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3</td>\n",
              "      <td>Diamond</td>\n",
              "      <td>18.775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>215</td>\n",
              "      <td>90</td>\n",
              "      <td>10</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3</td>\n",
              "      <td>Diamond</td>\n",
              "      <td>7.625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3caffd64-cfad-4e4d-acb7-48ee89b8f662')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3caffd64-cfad-4e4d-acb7-48ee89b8f662 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3caffd64-cfad-4e4d-acb7-48ee89b8f662');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7aa44795-2e66-432e-b78d-aac725398aaa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aa44795-2e66-432e-b78d-aac725398aaa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7aa44795-2e66-432e-b78d-aac725398aaa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 92,\n  \"fields\": [\n    {\n      \"column\": \"Extruder_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 215,\n        \"max\": 225,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          215,\n          220,\n          225\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Printing_speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 75,\n        \"max\": 150,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          90,\n          100,\n          125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Infill_density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 5,\n        \"max\": 50,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          45,\n          10,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Layer_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.031277162108561206,\n        \"min\": 0.15,\n        \"max\": 0.25,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2,\n          0.25,\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wall_layer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Infill_pattern\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Other\",\n          \"Shark\",\n          \"Diamond\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Average_tensile_strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.034507160251911,\n        \"min\": 3.31,\n        \"max\": 36.6,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          36.6,\n          18.775,\n          34.03\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kv7WbUQ0h6d",
        "outputId": "ea18ef5b-2c88-4cfc-b2fe-6b54904275a4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashiqurrahmankhan21st/NODE/refs/heads/main/FFF%20Data.csv\")\n",
        "X = df.drop(columns=[\"Average_tensile_strength\"])\n",
        "y = df[\"Average_tensile_strength\"]"
      ],
      "metadata": {
        "id": "qh4S4p9b5xjz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_y = StandardScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()"
      ],
      "metadata": {
        "id": "Sf7jhO6O6VQb"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical and numerical columns\n",
        "categorical_cols = [\"Infill_pattern\"]\n",
        "numeric_cols = [col for col in X.columns if col not in categorical_cols]"
      ],
      "metadata": {
        "id": "9XnmOm3_5ziD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numeric_cols),\n",
        "    (\"cat\", OneHotEncoder(sparse_output=False), categorical_cols)\n",
        "])\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UG-N7AkN51tl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=16)"
      ],
      "metadata": {
        "id": "n9gas3A7537d"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oblivious Decision Tree Layer\n",
        "class ObliviousDecisionTreeLayer(nn.Module):\n",
        "    def __init__(self, input_dim, num_trees, tree_depth):\n",
        "        super().__init__()\n",
        "        self.num_leafs = 2 ** tree_depth\n",
        "        self.feature_selectors = nn.Parameter(torch.randn(num_trees, tree_depth, input_dim))\n",
        "        self.feature_bias = nn.Parameter(torch.zeros(num_trees, tree_depth))\n",
        "        self.leaf_scores = nn.Parameter(torch.randn(num_trees, self.num_leafs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reshape input for batch matrix multiplication\n",
        "        x_expanded = x.unsqueeze(1).unsqueeze(2)  # [batch, 1, 1, input_dim]\n",
        "        w = self.feature_selectors.unsqueeze(0)   # [1, num_trees, tree_depth, input_dim]\n",
        "        logits = (x_expanded * w).sum(dim=-1) + self.feature_bias.unsqueeze(0)  # [batch, num_trees, tree_depth]\n",
        "        gates = torch.sigmoid(logits)\n",
        "        for d in range(gates.shape[2]):\n",
        "            if d == 0:\n",
        "                probs = torch.stack([1 - gates[:, :, d], gates[:, :, d]], dim=-1)\n",
        "            else:\n",
        "                probs = torch.cat([\n",
        "                    probs * (1 - gates[:, :, d]).unsqueeze(-1),\n",
        "                    probs * gates[:, :, d].unsqueeze(-1)\n",
        "                ], dim=-1)\n",
        "        return torch.sum(probs * self.leaf_scores.unsqueeze(0), dim=-1)"
      ],
      "metadata": {
        "id": "I8u6UKcI57pk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full NODE model\n",
        "class NODE(nn.Module):\n",
        "    def __init__(self, input_dim, num_trees=8, depth=3):\n",
        "        super().__init__()\n",
        "        self.tree1 = ObliviousDecisionTreeLayer(input_dim=input_dim, num_trees=num_trees, tree_depth=depth)\n",
        "        self.tree2 = ObliviousDecisionTreeLayer(input_dim=num_trees, num_trees=num_trees, tree_depth=depth)\n",
        "        self.tree3 = ObliviousDecisionTreeLayer(input_dim=num_trees, num_trees=num_trees, tree_depth=depth)\n",
        "        self.out = nn.Linear(num_trees, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tree1(x)\n",
        "        x = self.tree2(x)\n",
        "        x = self.tree3(x)\n",
        "        return self.out(x)"
      ],
      "metadata": {
        "id": "v3JEtW_25_Vm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "input_dim = X_train.shape[1]\n",
        "model = NODE(input_dim=input_dim, num_trees=32, depth=4) #'num_trees': 32, 'depth': 4, 'lr': 0.00994460910700778\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00994460910700778)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "-gT5owaP6CHU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaYWBLy56E0M",
        "outputId": "98e9937f-27f0-45af-fb15-495d91063791"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 4212.0243\n",
            "Epoch 2: Train Loss = 3847.5358\n",
            "Epoch 3: Train Loss = 3460.1953\n",
            "Epoch 4: Train Loss = 2978.8969\n",
            "Epoch 5: Train Loss = 2389.2361\n",
            "Epoch 6: Train Loss = 1742.7714\n",
            "Epoch 7: Train Loss = 1132.8775\n",
            "Epoch 8: Train Loss = 659.0740\n",
            "Epoch 9: Train Loss = 361.4209\n",
            "Epoch 10: Train Loss = 215.6336\n",
            "Epoch 11: Train Loss = 152.4605\n",
            "Epoch 12: Train Loss = 116.2104\n",
            "Epoch 13: Train Loss = 96.3927\n",
            "Epoch 14: Train Loss = 71.1989\n",
            "Epoch 15: Train Loss = 56.2371\n",
            "Epoch 16: Train Loss = 51.2663\n",
            "Epoch 17: Train Loss = 45.2870\n",
            "Epoch 18: Train Loss = 40.5118\n",
            "Epoch 19: Train Loss = 37.2660\n",
            "Epoch 20: Train Loss = 35.1721\n",
            "Epoch 21: Train Loss = 33.3349\n",
            "Epoch 22: Train Loss = 32.0172\n",
            "Epoch 23: Train Loss = 30.8635\n",
            "Epoch 24: Train Loss = 29.9279\n",
            "Epoch 25: Train Loss = 29.2121\n",
            "Epoch 26: Train Loss = 28.5154\n",
            "Epoch 27: Train Loss = 27.9054\n",
            "Epoch 28: Train Loss = 27.4077\n",
            "Epoch 29: Train Loss = 26.9632\n",
            "Epoch 30: Train Loss = 26.5673\n",
            "Epoch 31: Train Loss = 26.2653\n",
            "Epoch 32: Train Loss = 26.0101\n",
            "Epoch 33: Train Loss = 25.7678\n",
            "Epoch 34: Train Loss = 25.5442\n",
            "Epoch 35: Train Loss = 25.3514\n",
            "Epoch 36: Train Loss = 25.1839\n",
            "Epoch 37: Train Loss = 25.0322\n",
            "Epoch 38: Train Loss = 24.8893\n",
            "Epoch 39: Train Loss = 24.7517\n",
            "Epoch 40: Train Loss = 24.6179\n",
            "Epoch 41: Train Loss = 24.4836\n",
            "Epoch 42: Train Loss = 24.3393\n",
            "Epoch 43: Train Loss = 24.1668\n",
            "Epoch 44: Train Loss = 23.9255\n",
            "Epoch 45: Train Loss = 23.5356\n",
            "Epoch 46: Train Loss = 22.9942\n",
            "Epoch 47: Train Loss = 22.5544\n",
            "Epoch 48: Train Loss = 22.3190\n",
            "Epoch 49: Train Loss = 22.2193\n",
            "Epoch 50: Train Loss = 22.1179\n",
            "Epoch 51: Train Loss = 22.0539\n",
            "Epoch 52: Train Loss = 22.0076\n",
            "Epoch 53: Train Loss = 21.9592\n",
            "Epoch 54: Train Loss = 21.9106\n",
            "Epoch 55: Train Loss = 21.8665\n",
            "Epoch 56: Train Loss = 21.8290\n",
            "Epoch 57: Train Loss = 21.7980\n",
            "Epoch 58: Train Loss = 21.7719\n",
            "Epoch 59: Train Loss = 21.7481\n",
            "Epoch 60: Train Loss = 21.7245\n",
            "Epoch 61: Train Loss = 21.6997\n",
            "Epoch 62: Train Loss = 21.6735\n",
            "Epoch 63: Train Loss = 21.6466\n",
            "Epoch 64: Train Loss = 21.6199\n",
            "Epoch 65: Train Loss = 21.5942\n",
            "Epoch 66: Train Loss = 21.5705\n",
            "Epoch 67: Train Loss = 21.5488\n",
            "Epoch 68: Train Loss = 21.5289\n",
            "Epoch 69: Train Loss = 21.5101\n",
            "Epoch 70: Train Loss = 21.4920\n",
            "Epoch 71: Train Loss = 21.4744\n",
            "Epoch 72: Train Loss = 21.4572\n",
            "Epoch 73: Train Loss = 21.4406\n",
            "Epoch 74: Train Loss = 21.4244\n",
            "Epoch 75: Train Loss = 21.4088\n",
            "Epoch 76: Train Loss = 21.3936\n",
            "Epoch 77: Train Loss = 21.3789\n",
            "Epoch 78: Train Loss = 21.3646\n",
            "Epoch 79: Train Loss = 21.3508\n",
            "Epoch 80: Train Loss = 21.3374\n",
            "Epoch 81: Train Loss = 21.3244\n",
            "Epoch 82: Train Loss = 21.3119\n",
            "Epoch 83: Train Loss = 21.2997\n",
            "Epoch 84: Train Loss = 21.2878\n",
            "Epoch 85: Train Loss = 21.2762\n",
            "Epoch 86: Train Loss = 21.2648\n",
            "Epoch 87: Train Loss = 21.2536\n",
            "Epoch 88: Train Loss = 21.2425\n",
            "Epoch 89: Train Loss = 21.2315\n",
            "Epoch 90: Train Loss = 21.2206\n",
            "Epoch 91: Train Loss = 21.2096\n",
            "Epoch 92: Train Loss = 21.1985\n",
            "Epoch 93: Train Loss = 21.1871\n",
            "Epoch 94: Train Loss = 21.1755\n",
            "Epoch 95: Train Loss = 21.1633\n",
            "Epoch 96: Train Loss = 21.1504\n",
            "Epoch 97: Train Loss = 21.1364\n",
            "Epoch 98: Train Loss = 21.1208\n",
            "Epoch 99: Train Loss = 21.1026\n",
            "Epoch 100: Train Loss = 21.0806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test_tensor)\n",
        "    test_loss = criterion(preds, y_test_tensor).item()\n",
        "    print(f\"\\nTest MSE: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdguBjxn219V",
        "outputId": "fca49446-0239-4110-e87d-7305f706672d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test MSE: 49.6380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xuzCYXP_3o7t"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    num_trees = trial.suggest_int(\"num_trees\", 4, 32)\n",
        "    depth = trial.suggest_int(\"depth\", 2, 5)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    # Define model with suggested hyperparameters\n",
        "    model = NODE(input_dim=X_train.shape[1], num_trees=num_trees, depth=depth)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Train for a few epochs\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate on test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_test_tensor)\n",
        "        mse = mean_squared_error(y_test_tensor.numpy(), preds.numpy())\n",
        "    return mse\n",
        "\n",
        "# Run Bayesian optimization using Optuna\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "# Best result\n",
        "best_params = study.best_params\n",
        "best_score = study.best_value\n",
        "\n",
        "(best_params, best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBQ4ZySd7Xan",
        "outputId": "ca70732a-2890-4ce4-e494-2d29489f67ac"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-08 00:11:23,046] A new study created in memory with name: no-name-5fcdad50-5f27-4626-bf8a-b20f2fded9cd\n",
            "[I 2025-06-08 00:11:23,373] Trial 0 finished with value: 189.34512329101562 and parameters: {'num_trees': 30, 'depth': 3, 'lr': 0.00822469325296412}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:23,692] Trial 1 finished with value: 761.4637451171875 and parameters: {'num_trees': 27, 'depth': 5, 'lr': 0.0028291179736444705}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:24,098] Trial 2 finished with value: 463.753662109375 and parameters: {'num_trees': 30, 'depth': 4, 'lr': 0.0049953999517347095}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:24,309] Trial 3 finished with value: 904.064453125 and parameters: {'num_trees': 28, 'depth': 3, 'lr': 0.00021246416371760375}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:24,472] Trial 4 finished with value: 634.716552734375 and parameters: {'num_trees': 18, 'depth': 2, 'lr': 0.004361265464156476}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:24,807] Trial 5 finished with value: 922.9992065429688 and parameters: {'num_trees': 10, 'depth': 4, 'lr': 0.00020656115429183242}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:25,187] Trial 6 finished with value: 872.3285522460938 and parameters: {'num_trees': 5, 'depth': 4, 'lr': 0.0030267456157200444}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:25,455] Trial 7 finished with value: 914.747314453125 and parameters: {'num_trees': 14, 'depth': 2, 'lr': 0.0006030149588480849}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:25,759] Trial 8 finished with value: 870.03173828125 and parameters: {'num_trees': 5, 'depth': 3, 'lr': 0.0030741361052997423}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:26,382] Trial 9 finished with value: 434.029052734375 and parameters: {'num_trees': 14, 'depth': 4, 'lr': 0.007449249638465913}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:26,924] Trial 10 finished with value: 882.9462280273438 and parameters: {'num_trees': 23, 'depth': 5, 'lr': 0.000762650057984209}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:27,427] Trial 11 finished with value: 221.4111328125 and parameters: {'num_trees': 19, 'depth': 3, 'lr': 0.008899302092765415}. Best is trial 0 with value: 189.34512329101562.\n",
            "[I 2025-06-08 00:11:27,785] Trial 12 finished with value: 132.58473205566406 and parameters: {'num_trees': 22, 'depth': 3, 'lr': 0.0099569420623071}. Best is trial 12 with value: 132.58473205566406.\n",
            "[I 2025-06-08 00:11:28,210] Trial 13 finished with value: 810.9772338867188 and parameters: {'num_trees': 32, 'depth': 2, 'lr': 0.0015755196920535872}. Best is trial 12 with value: 132.58473205566406.\n",
            "[I 2025-06-08 00:11:28,736] Trial 14 finished with value: 829.5287475585938 and parameters: {'num_trees': 24, 'depth': 3, 'lr': 0.0016070231810876986}. Best is trial 12 with value: 132.58473205566406.\n",
            "[I 2025-06-08 00:11:29,491] Trial 15 finished with value: 194.6817626953125 and parameters: {'num_trees': 23, 'depth': 3, 'lr': 0.009709000836075943}. Best is trial 12 with value: 132.58473205566406.\n",
            "[I 2025-06-08 00:11:30,589] Trial 16 finished with value: 920.6560668945312 and parameters: {'num_trees': 26, 'depth': 2, 'lr': 0.00012153853197454897}. Best is trial 12 with value: 132.58473205566406.\n",
            "[I 2025-06-08 00:11:32,028] Trial 17 finished with value: 616.0534057617188 and parameters: {'num_trees': 19, 'depth': 3, 'lr': 0.004961547130136773}. Best is trial 12 with value: 132.58473205566406.\n",
            "[I 2025-06-08 00:11:33,287] Trial 18 finished with value: 825.15869140625 and parameters: {'num_trees': 32, 'depth': 4, 'lr': 0.0013898336483749098}. Best is trial 12 with value: 132.58473205566406.\n",
            "[I 2025-06-08 00:11:33,761] Trial 19 finished with value: 446.0438537597656 and parameters: {'num_trees': 21, 'depth': 2, 'lr': 0.005751839783281213}. Best is trial 12 with value: 132.58473205566406.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'num_trees': 22, 'depth': 3, 'lr': 0.0099569420623071}, 132.58473205566406)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params['depth']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgtSGLwf4rcM",
        "outputId": "9e3a4674-21f2-41fc-d6b3-8f8a34661e11"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "input_dim = X_train.shape[1]\n",
        "model = NODE(input_dim=input_dim, num_trees=best_params['num_trees'], depth=best_params['depth']) #'num_trees': 32, 'depth': 4, 'lr': 0.00994460910700778\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=best_params['lr'])\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test_tensor)\n",
        "    test_loss = criterion(preds, y_test_tensor).item()\n",
        "    print(f\"\\nTest MSE: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnb0tHcB4cHh",
        "outputId": "91d912fc-0d0c-49ac-bb4c-3d9f36f6e63c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 4109.4975\n",
            "Epoch 2: Train Loss = 3739.5243\n",
            "Epoch 3: Train Loss = 3368.6086\n",
            "Epoch 4: Train Loss = 2966.4324\n",
            "Epoch 5: Train Loss = 2527.5664\n",
            "Epoch 6: Train Loss = 2071.6934\n",
            "Epoch 7: Train Loss = 1623.1640\n",
            "Epoch 8: Train Loss = 1227.6982\n",
            "Epoch 9: Train Loss = 911.3263\n",
            "Epoch 10: Train Loss = 661.3268\n",
            "Epoch 11: Train Loss = 469.6521\n",
            "Epoch 12: Train Loss = 320.1546\n",
            "Epoch 13: Train Loss = 213.7352\n",
            "Epoch 14: Train Loss = 148.9358\n",
            "Epoch 15: Train Loss = 119.1144\n",
            "Epoch 16: Train Loss = 100.5185\n",
            "Epoch 17: Train Loss = 93.2676\n",
            "Epoch 18: Train Loss = 90.4434\n",
            "Epoch 19: Train Loss = 85.9043\n",
            "Epoch 20: Train Loss = 79.1281\n",
            "Epoch 21: Train Loss = 72.7636\n",
            "Epoch 22: Train Loss = 67.4568\n",
            "Epoch 23: Train Loss = 60.7032\n",
            "Epoch 24: Train Loss = 54.1709\n",
            "Epoch 25: Train Loss = 49.0842\n",
            "Epoch 26: Train Loss = 45.0192\n",
            "Epoch 27: Train Loss = 42.0317\n",
            "Epoch 28: Train Loss = 39.8705\n",
            "Epoch 29: Train Loss = 38.2870\n",
            "Epoch 30: Train Loss = 36.9415\n",
            "Epoch 31: Train Loss = 35.7199\n",
            "Epoch 32: Train Loss = 34.5626\n",
            "Epoch 33: Train Loss = 33.5063\n",
            "Epoch 34: Train Loss = 32.5931\n",
            "Epoch 35: Train Loss = 31.8234\n",
            "Epoch 36: Train Loss = 31.1635\n",
            "Epoch 37: Train Loss = 30.5964\n",
            "Epoch 38: Train Loss = 30.1183\n",
            "Epoch 39: Train Loss = 29.7098\n",
            "Epoch 40: Train Loss = 29.3395\n",
            "Epoch 41: Train Loss = 28.9887\n",
            "Epoch 42: Train Loss = 28.6534\n",
            "Epoch 43: Train Loss = 28.3298\n",
            "Epoch 44: Train Loss = 28.0071\n",
            "Epoch 45: Train Loss = 27.6727\n",
            "Epoch 46: Train Loss = 27.3083\n",
            "Epoch 47: Train Loss = 26.8783\n",
            "Epoch 48: Train Loss = 26.3352\n",
            "Epoch 49: Train Loss = 25.7197\n",
            "Epoch 50: Train Loss = 25.2505\n",
            "Epoch 51: Train Loss = 24.9581\n",
            "Epoch 52: Train Loss = 24.6945\n",
            "Epoch 53: Train Loss = 24.4401\n",
            "Epoch 54: Train Loss = 24.2110\n",
            "Epoch 55: Train Loss = 24.0185\n",
            "Epoch 56: Train Loss = 23.8532\n",
            "Epoch 57: Train Loss = 23.7056\n",
            "Epoch 58: Train Loss = 23.5731\n",
            "Epoch 59: Train Loss = 23.4493\n",
            "Epoch 60: Train Loss = 23.3330\n",
            "Epoch 61: Train Loss = 23.2277\n",
            "Epoch 62: Train Loss = 23.1350\n",
            "Epoch 63: Train Loss = 23.0535\n",
            "Epoch 64: Train Loss = 22.9805\n",
            "Epoch 65: Train Loss = 22.9126\n",
            "Epoch 66: Train Loss = 22.8465\n",
            "Epoch 67: Train Loss = 22.7818\n",
            "Epoch 68: Train Loss = 22.7187\n",
            "Epoch 69: Train Loss = 22.6576\n",
            "Epoch 70: Train Loss = 22.5991\n",
            "Epoch 71: Train Loss = 22.5434\n",
            "Epoch 72: Train Loss = 22.4906\n",
            "Epoch 73: Train Loss = 22.4407\n",
            "Epoch 74: Train Loss = 22.3936\n",
            "Epoch 75: Train Loss = 22.3487\n",
            "Epoch 76: Train Loss = 22.3061\n",
            "Epoch 77: Train Loss = 22.2656\n",
            "Epoch 78: Train Loss = 22.2272\n",
            "Epoch 79: Train Loss = 22.1910\n",
            "Epoch 80: Train Loss = 22.1570\n",
            "Epoch 81: Train Loss = 22.1253\n",
            "Epoch 82: Train Loss = 22.0957\n",
            "Epoch 83: Train Loss = 22.0682\n",
            "Epoch 84: Train Loss = 22.0426\n",
            "Epoch 85: Train Loss = 22.0188\n",
            "Epoch 86: Train Loss = 21.9967\n",
            "Epoch 87: Train Loss = 21.9761\n",
            "Epoch 88: Train Loss = 21.9568\n",
            "Epoch 89: Train Loss = 21.9388\n",
            "Epoch 90: Train Loss = 21.9217\n",
            "Epoch 91: Train Loss = 21.9057\n",
            "Epoch 92: Train Loss = 21.8904\n",
            "Epoch 93: Train Loss = 21.8758\n",
            "Epoch 94: Train Loss = 21.8619\n",
            "Epoch 95: Train Loss = 21.8486\n",
            "Epoch 96: Train Loss = 21.8358\n",
            "Epoch 97: Train Loss = 21.8234\n",
            "Epoch 98: Train Loss = 21.8115\n",
            "Epoch 99: Train Loss = 21.8000\n",
            "Epoch 100: Train Loss = 21.7888\n",
            "\n",
            "Test MSE: 82.3744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_test_tensor.numpy(), preds.numpy())\n",
        "print(\"R^2 Score:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phK1YIVp5bux",
        "outputId": "40f4ab96-bc7d-438f-b170-9a157c3d01ca"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 Score: 0.25046950578689575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGx4xNnP8gX7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}